# üöÄ API de Infer√™ncia de Modelos ML v2 - Projeto Final

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115.13-green.svg)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://docker.com)
[![Render](https://img.shields.io/badge/Deploy-Render-purple.svg)](https://render.com)

## üìã √çndice

- [Sobre o Projeto](#sobre-o-projeto)
- [Arquitetura](#arquitetura)
- [Features v2](#features-v2)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Instala√ß√£o Local](#instala√ß√£o-local)
- [Deploy no Render](#deploy-no-render)
- [Endpoints](#endpoints)
- [Autentica√ß√£o](#autentica√ß√£o)
- [Rate Limiting](#rate-limiting)
- [M√©tricas e Monitoramento](#m√©tricas-e-monitoramento)
- [Testes](#testes)

---

## üìñ Sobre o Projeto

Este √© o **Projeto Final** do curso de APIs para Infer√™ncia de Modelos de Machine Learning. 

A API v2 evolui a vers√£o b√°sica (aula_06) adicionando:
- üõ°Ô∏è **Rate Limiting** para prote√ß√£o contra abuso
- üìä **M√©tricas Prometheus** para observabilidade
- üìù **Logs Estruturados (JSON)** para an√°lise
- üîÑ **Batch Prediction** para processamento em lote
- üê≥ **Stack completa** com Docker Compose (API + Prometheus + Grafana)

---

## üèóÔ∏è Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                              CLIENTES                                    ‚îÇ
‚îÇ                    (Web Apps, Mobile, Scripts)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           API GATEWAY                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   CORS      ‚îÇ  ‚îÇ   Logging   ‚îÇ  ‚îÇ    Rate     ‚îÇ  ‚îÇ   JWT       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Middleware ‚îÇ‚Üí ‚îÇ  Middleware ‚îÇ‚Üí ‚îÇ   Limiter   ‚îÇ‚Üí ‚îÇ   Auth      ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         ENDPOINTS                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   /login    ‚îÇ  ‚îÇ  /predict   ‚îÇ  ‚îÇ  /predict/  ‚îÇ  ‚îÇ   /model/   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ    POST     ‚îÇ  ‚îÇ    POST     ‚îÇ  ‚îÇ    batch    ‚îÇ  ‚îÇ    info     ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      ML MODEL (Scikit-learn)                            ‚îÇ
‚îÇ                       üå∏ Iris Classifier                                 ‚îÇ
‚îÇ                    (Random Forest / Logistic)                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       OBSERVABILIDADE                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ  ‚îÇ Prometheus  ‚îÇ  ‚îÇ   Grafana   ‚îÇ  ‚îÇ    Logs     ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ  :9090      ‚îÇ‚Üí ‚îÇ   :3000     ‚îÇ  ‚îÇ   (JSON)    ‚îÇ                     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚ú® Features v2

| Feature | v1 (aula_06) | v2 (aula_08) |
|---------|:------------:|:------------:|
| FastAPI + JWT Auth | ‚úÖ | ‚úÖ |
| Docker + Render Deploy | ‚úÖ | ‚úÖ |
| Rate Limiting | ‚ùå | ‚úÖ |
| Logs Estruturados (JSON) | ‚ùå | ‚úÖ |
| M√©tricas Prometheus | ‚ùå | ‚úÖ |
| Alertas Configurados | ‚ùå | ‚úÖ |
| Batch Prediction | ‚ùå | ‚úÖ |
| Dashboard Grafana | ‚ùå | ‚úÖ |
| Trace ID por Request | ‚ùå | ‚úÖ |

---

## üìÅ Estrutura do Projeto

```
aula_08/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # FastAPI bootstrap + routers
‚îÇ   ‚îú‚îÄ‚îÄ core.py               # Configs globais (vers√£o, settings)
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py            # Modelos Pydantic (request/response)
‚îÇ   ‚îú‚îÄ‚îÄ model_loader.py       # Carrega modelo ML + labels
‚îÇ   ‚îú‚îÄ‚îÄ auth.py               # JWT authentication
‚îÇ   ‚îú‚îÄ‚îÄ logging_config.py     # Logs estruturados JSON
‚îÇ   ‚îú‚îÄ‚îÄ middleware.py         # LoggingMiddleware + trace_id
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py            # M√©tricas Prometheus customizadas
‚îÇ   ‚îú‚îÄ‚îÄ rate_limit.py         # Configura√ß√£o slowapi
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ iris_model.pkl    # Modelo treinado
‚îÇ   ‚îî‚îÄ‚îÄ routers/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ auth.py           # Rotas: /login, /me
‚îÇ       ‚îú‚îÄ‚îÄ info.py           # Rotas: /, /health, /model/info
‚îÇ       ‚îî‚îÄ‚îÄ predict.py        # Rotas: /predict, /predict/batch
‚îú‚îÄ‚îÄ prometheus/
‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml        # Configura√ß√£o do Prometheus
‚îÇ   ‚îî‚îÄ‚îÄ alerts.yml            # Regras de alertas
‚îú‚îÄ‚îÄ docker-compose.yml        # Stack local (API + Prometheus + Grafana)
‚îú‚îÄ‚îÄ Dockerfile                # Build da imagem
‚îú‚îÄ‚îÄ render.yaml               # Blueprint para Render
‚îú‚îÄ‚îÄ requirements.txt          # Depend√™ncias Python
‚îî‚îÄ‚îÄ README.md                 # Este arquivo
```

---

## üîß Instala√ß√£o Local

### Pr√©-requisitos

- Python 3.11+
- Docker e Docker Compose
- Git

### Op√ß√£o 1: Desenvolvimento Local (Python)

```bash
# Clone o reposit√≥rio
git clone https://github.com/iohpedro/API-INFERENCIA-MODELOS.git
cd API-INFERENCIA-MODELOS/aula_08

# Crie ambiente virtual
python -m venv venv

# Ative o ambiente
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Instale depend√™ncias
pip install -r requirements.txt

# Execute a API
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Op√ß√£o 2: Docker Compose (Recomendado)

```bash
# Clone o reposit√≥rio
git clone https://github.com/iohpedro/API-INFERENCIA-MODELOS.git
cd API-INFERENCIA-MODELOS/aula_08

# Suba toda a stack
docker-compose up --build

# Acesse:
# - API:        http://localhost:8000
# - Docs:       http://localhost:8000/docs
# - Prometheus: http://localhost:9090
# - Grafana:    http://localhost:3000 (admin/admin)
```

---

## ‚òÅÔ∏è Deploy no Render

Nesta vers√£o, voc√™ pode subir **a mesma stack do docker-compose** no Render, mas em **servi√ßos separados** (cada um com sua pr√≥pria URL):

- **API**: `https://api-iris-v2.onrender.com`
- **Prometheus**: `https://prometheus-iris-v2.onrender.com`
- **Grafana**: `https://grafana-iris-v2.onrender.com`

> Observa√ß√£o: no Render n√£o existe `docker-compose up`. O equivalente √© criar m√∫ltiplos **Web Services** (um por container) ‚Äî manualmente ou via Blueprint (`render.yaml`).

### M√©todo 1: Blueprint (Autom√°tico)

1. Fa√ßa fork do reposit√≥rio no GitHub
2. Acesse [render.com](https://render.com) e fa√ßa login
3. V√° em **Blueprints** ‚Üí **New Blueprint Instance**
4. Conecte seu reposit√≥rio
5. Selecione o arquivo `aula_08/render.yaml`
6. O Render criar√° **3 servi√ßos** automaticamente (API + Prometheus + Grafana)

Ap√≥s subir:
- Prometheus j√° vem configurado para fazer scrape da API em `/metrics`.
- Grafana j√° vem com datasource do Prometheus provisionado.

### M√©todo 2: Deploy Manual

1. Acesse [render.com](https://render.com)
2. **New** ‚Üí **Web Service**
3. Conecte o reposit√≥rio GitHub
4. Crie **3 Web Services**:

**Servi√ßo 1 ‚Äî API**
- **Name**: `api-iris-v2`
- **Root Directory**: `aula_08`
- **Runtime**: Docker
- **Dockerfile Path**: `aula_08/Dockerfile`

**Servi√ßo 2 ‚Äî Prometheus**
- **Name**: `prometheus-iris-v2`
- **Root Directory**: `aula_08/prometheus`
- **Runtime**: Docker
- **Dockerfile Path**: `aula_08/prometheus/Dockerfile`
- **Env Vars**:
  - `API_TARGET=api-iris-v2.onrender.com`
  - `API_SCHEME=https`
  - `SCRAPE_INTERVAL=15s`

**Servi√ßo 3 ‚Äî Grafana**
- **Name**: `grafana-iris-v2`
- **Root Directory**: `aula_08/grafana`
- **Runtime**: Docker
- **Dockerfile Path**: `aula_08/grafana/Dockerfile`
- **Env Vars**:
  - `GF_SECURITY_ADMIN_USER=admin`
  - `GF_SECURITY_ADMIN_PASSWORD=admin`
  - `GF_USERS_ALLOW_SIGN_UP=false`
  - `PROMETHEUS_URL=https://prometheus-iris-v2.onrender.com`

5. Clique em **Create Web Service** para cada um.

---

## üîå Endpoints

### P√∫blicos

| M√©todo | Endpoint | Descri√ß√£o |
|--------|----------|-----------|
| GET | `/` | Informa√ß√µes da API |
| GET | `/health` | Health check |
| GET | `/docs` | Swagger UI |
| GET | `/redoc` | ReDoc |
| POST | `/login` | Obter token JWT |

### Protegidos (JWT)

| M√©todo | Endpoint | Descri√ß√£o | Rate Limit |
|--------|----------|-----------|------------|
| POST | `/predict` | Predi√ß√£o individual | 30/min |
| POST | `/predict/batch` | Predi√ß√£o em lote | 10/min |
| GET | `/model/info` | Info do modelo | 60/min |

### M√©tricas

| M√©todo | Endpoint | Descri√ß√£o |
|--------|----------|-----------|
| GET | `/metrics` | M√©tricas Prometheus |

---

## üîê Autentica√ß√£o

A API usa **JWT (JSON Web Tokens)** para autentica√ß√£o.

### Obter Token

```bash
curl -X POST http://localhost:8000/login \
  -H "Content-Type: application/json" \
  -d '{"username": "admin", "password": "secret123"}'
```

**Resposta:**
```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer",
  "expires_in": 1800
}
```

### Usar Token

```bash
curl -X POST http://localhost:8000/predict \
  -H "Authorization: Bearer SEU_TOKEN_AQUI" \
  -H "Content-Type: application/json" \
  -d '{
    "sepal_length": 5.1,
    "sepal_width": 3.5,
    "petal_length": 1.4,
    "petal_width": 0.2
  }'
```

---

## ‚è±Ô∏è Rate Limiting

A API implementa rate limiting para proteger contra abuso:

| Endpoint | Limite | Janela |
|----------|--------|--------|
| `/login` | 10 | 1 minuto |
| `/predict` | 30 | 1 minuto |
| `/predict/batch` | 10 | 1 minuto |
| Demais | 60 | 1 minuto |

### Resposta quando limite excedido

```json
{
  "error": "Rate limit exceeded",
  "detail": "30 per 1 minute",
  "retry_after": 45
}
```

**Headers inclu√≠dos:**
- `X-RateLimit-Limit`: Limite total
- `X-RateLimit-Remaining`: Requisi√ß√µes restantes
- `X-RateLimit-Reset`: Timestamp de reset

---

## üìä M√©tricas e Monitoramento

### M√©tricas Dispon√≠veis

| M√©trica | Tipo | Descri√ß√£o |
|---------|------|-----------|
| `iris_predictions_total` | Counter | Total de predi√ß√µes |
| `iris_batch_predictions_total` | Counter | Total de batches |
| `iris_login_attempts_total` | Counter | Tentativas de login |
| `iris_rate_limit_exceeded_total` | Counter | Rate limits atingidos |
| `iris_prediction_latency_seconds` | Histogram | Lat√™ncia de predi√ß√£o |
| `iris_batch_prediction_latency_seconds` | Histogram | Lat√™ncia de batch |
| `iris_model_loaded` | Gauge | Status do modelo |
| `iris_avg_confidence` | Gauge | Confian√ßa m√©dia |

### Alertas Configurados

1. **APIDown**: API n√£o respondendo por 1 minuto
2. **HighErrorRate**: Taxa de erro > 5% por 5 minutos
3. **HighLatency**: P95 lat√™ncia > 1s por 5 minutos
4. **ModelNotLoaded**: Modelo n√£o carregado
5. **HighRateLimitBlocks**: > 100 bloqueios/5min

### Acessando Grafana

1. Acesse `http://localhost:3000`
2. Login: `admin` / `admin`
3. Adicione Data Source ‚Üí Prometheus ‚Üí URL: `http://prometheus:9090`
4. Importe ou crie dashboards

---

## üß™ Testes

### Teste de Predi√ß√£o Individual

```bash
# Login
TOKEN=$(curl -s -X POST http://localhost:8000/login \
  -H "Content-Type: application/json" \
  -d '{"username": "admin", "password": "secret123"}' | jq -r '.access_token')

# Predi√ß√£o
curl -X POST http://localhost:8000/predict \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "sepal_length": 5.1,
    "sepal_width": 3.5,
    "petal_length": 1.4,
    "petal_width": 0.2
  }'
```

### Teste de Batch Prediction

```bash
curl -X POST http://localhost:8000/predict/batch \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "samples": [
      {"sepal_length": 5.1, "sepal_width": 3.5, "petal_length": 1.4, "petal_width": 0.2},
      {"sepal_length": 7.0, "sepal_width": 3.2, "petal_length": 4.7, "petal_width": 1.4},
      {"sepal_length": 6.3, "sepal_width": 3.3, "petal_length": 6.0, "petal_width": 2.5}
    ]
  }'
```

### Teste de Rate Limiting

```bash
# Execute m√∫ltiplas requisi√ß√µes rapidamente
for i in {1..35}; do
  echo "Request $i:"
  curl -s -o /dev/null -w "%{http_code}\n" \
    -X POST http://localhost:8000/predict \
    -H "Authorization: Bearer $TOKEN" \
    -H "Content-Type: application/json" \
    -d '{"sepal_length": 5.1, "sepal_width": 3.5, "petal_length": 1.4, "petal_width": 0.2}'
done
# Ap√≥s 30 requisi√ß√µes, voc√™ ver√° 429 (Too Many Requests)
```

---

## üìù Vari√°veis de Ambiente

| Vari√°vel | Descri√ß√£o | Default |
|----------|-----------|---------|
| `SECRET_KEY` | Chave para JWT | `dev-secret-key` |
| `ALGORITHM` | Algoritmo JWT | `HS256` |
| `ACCESS_TOKEN_EXPIRE_MINUTES` | Expira√ß√£o token | `30` |
| `RATE_LIMIT_DEFAULT` | Limite padr√£o/min | `60` |
| `RATE_LIMIT_PREDICT` | Limite predict/min | `30` |
| `RATE_LIMIT_BATCH` | Limite batch/min | `10` |
| `RATE_LIMIT_LOGIN` | Limite login/min | `10` |
| `LOG_LEVEL` | N√≠vel de log | `INFO` |
| `MODEL_VERSION` | Vers√£o do modelo | `2.0.0` |

---

## ü§ù Contribuindo

1. Fa√ßa fork do projeto
2. Crie uma branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudan√ßas (`git commit -m 'Add nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

---

## üìÑ Licen√ßa

Este projeto √© parte do curso de APIs para ML e est√° dispon√≠vel para fins educacionais.

---

## üë®‚Äçüè´ Autor
Professor Ioannis Eleftheriou -  https://www.linkedin.com/in/ioannispedroeleftheriou/  

Desenvolvido como material did√°tico para o curso de **APIs para Infer√™ncia de Modelos de Machine Learning**.

---

<p align="center">
  <strong>üéì Aula 08 - Projeto Final</strong><br>
  Evoluindo uma API de ML para Produ√ß√£o
</p>
